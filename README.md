## Chapter 1

## Chapter 2

## Chapter 3

1. The effectiveness of an SVM depends upon:
    * a. Selection of Kernel
    * b. Kernel Parameters
    * c. Soft Margin Parameter C
    * d. All of the above

Answer: (d)

2.  What do you mean by a hard margin?
    * a. The SVM allows high amount of error in classification
    * b. The SVM allows very low error in classification
    * c. Widen the margin and allows for violation
    * d. None of the above

Answer: (b)

3. What is Not the advantage of decision trees?
    * a. Simple to understand and to interpret
    * b. Effective in high dimensional spaces
    * c. Requires little data preparation
    * d. Performs well even if its assumptions are somewhat violated by the true model 
        from which the data were generated

Answer: (b)

4. A decision tree can be used to build models for 
    * a. Classification problems
    * b. Regression problems
    * c. None of the aboven
    * d. Both of the above
Answer: (d)

5.  To reduce underfitting of a Random Forest model, which of the following method can be used?
    * a. Increase minimum sample leaf value
    * b. Increase depth of trees
    * c. Increase the value of minimum samples to split
    * d. None of these

Answer: (b)


## Chapter 4


## Chapter 5
1. Which of the following is not fundamental dimensionality reduction technique for feature extraction?
    * a. ICA
    * b. standard PCA
    * c. LDA
    * d. kernel PCA  

Answer: (a)

2. Which of the following algorithms cannot be used for reducing the dimensionality of data?
    * a. t-SNE
    * b. PCA
    * c. LDA False
    * d. None of these

Answer: (d)

3. The most popularly used dimensionality reduction algorithm is Principal Component Analysis (PCA). Which of the following is/are true about PCA?
    * a. PCA is an unsupervised method.
    * b. It searches for the directions that data have the largest variance.
    * c. All principal components are orthogonal to each other
    * d. All of the above

Answer: (d)

4. Which of the following statement is correct for t-SNE and PCA?
    * a. t-SNE is linear whereas PCA is non-linear.
    * b. t-SNE is nonlinear whereas PCA is linear
    * c. t-SNE and PCA both are linear
    * d. t-SNE and PCA both are nonlinear

Answer: (b)

5. Which of the following is true about LDA?
    * a. LDA aims to maximize the distance between class and minimize the within class distance.
    * b. LDA aims to minimize both distance between class and distance within class.
    * c. LDA aims to minimize the distance between class and maximize the distance within class.
    * d. LDA aims to maximize both distance between class and distance within class.

Answer: (a)

## Chapter 6
1. What’s not the part of streamlining workflows with pipelines? 

    * a. Scaling dataset
    * b. Dimensionality Reduction
    * c. Spliting dataset into training set and test set
    * d. Learning Algorithm

Answer: (c)

2. What’s part of dataset worked for model selection in holdout method? 

    * a. Training dataset
    * b. Validation dataset
    * c. Test dataset
    * d. Original dataset

Answer: (b)

3. Which of the following options is/are true for K-fold cross-validation?
    * a. Increase in K will result in higher time required to cross validate the result.
    * b. Higher values of K will result in higher confidence on the cross-validation result as compared to lower value of K.
    * c. If K=N, then it is called Leave one out cross validation, where N is the number of observations.
    * d. All of the above  

Answer: (d)

4. Which of the following is true about bias and variance? 

    * a. High bias model means overfitting.
    * b. High variance model means underfitting.
    * c. If our model is too simple and has very few parameters then it may have low bias and low variance. 
    * d. If our model has large number of parameters then it’s going to have high variance and low bias.

Answer: (d)

5. Which of the following is not common way to address overfitting? 

    * a. Increase the number of parameters of the model
    * b. Collect more training data
    * c. Reduce the complexity of the model
    * d. Increase the regularization parameter

Answer: (a)
